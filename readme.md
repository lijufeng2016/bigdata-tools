# 说明

## 一、遇到的痛点

spark计算完后，存储结果hive表时，要限制小文件，数据量到达一定的时候，几十G，使用spark自带的算子repartition或coalesce算子来减少文件的数量，spark内部的中间过程会带来大量的网络IO、序列化&反序列化、shuffle，极大的降低了性能，目前处理跑任务的过程中，repartition占用的时间超过总时长的一半，成了不得不解决的痛点

## 二、解决方法

此工具的原理利用spark的分布式特性，把各个文件合并的进程打到各个计算节点，各个节点的合并逻辑自己实现，不需要走spark那一套逻辑，不需要维护hive表内部的结构，实现了分布式并行化的文件合并，大大提升性能

### 三、支持格式

目前只支持orc、parquet、text格式

